# Sample ArenaConfig - Evaluation configuration
apiVersion: omnia.altairalabs.ai/v1alpha1
kind: ArenaConfig
metadata:
  name: assertions-eval
  namespace: omnia-system
spec:
  sourceRef:
    name: promptkit-examples
  scenarios:
    include:
      - "scenarios/*.yaml"
    exclude:
      - "*-wip.yaml"
  providers:
    - name: claude-sonnet
    - name: openai-gpt4
  evaluation:
    timeout: "5m"
    maxRetries: 3
    concurrency: 2
    metrics:
      - latency
      - tokens
      - cost
